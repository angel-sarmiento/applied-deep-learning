{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "cassava-classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fc268cfc962b46618280c9a6e66a23bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1af4bec7a61543338eb09c52b998271a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ecbfd5e14d7b4a9a9ad2806e95483cf5",
              "IPY_MODEL_6667a669fb8b4ac4b9b97e85c1e1ffe6"
            ]
          }
        },
        "1af4bec7a61543338eb09c52b998271a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecbfd5e14d7b4a9a9ad2806e95483cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7aa229df6e2d4ceda560425324c68109",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9b6a0e98c7a46cfb5af7e7620fa3c23"
          }
        },
        "6667a669fb8b4ac4b9b97e85c1e1ffe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3a9478397ef340c5838f148a5412c80f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:56&lt;00:00, 1.80MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d083d823d88e4c04b08f91d18f2877e9"
          }
        },
        "7aa229df6e2d4ceda560425324c68109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9b6a0e98c7a46cfb5af7e7620fa3c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a9478397ef340c5838f148a5412c80f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d083d823d88e4c04b08f91d18f2877e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xKqoNjvkelI"
      },
      "source": [
        "# Cassava Disease Classification Using Transfer Learning with ResNet50 \n",
        "\n",
        "## Angel Sarmiento\n",
        "https://www.kaggle.com/c/cassava-disease/data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Introduction\n",
        "\n",
        "This programming assignment correspond to a real Kaggle context: iCassava 2019 Fine-Grained Visual Categorization Challenge.  \n",
        "\n",
        "\n",
        "### Problem Description\n",
        "\n",
        "As the 2nd largest provider of carbohydrates in Africa, cassava is a key food security crop grown by small-holder farmers because it can withstand harsh conditions. At least 80% of small-holder farmer households in Sub-Saharan Africa grow cassava and viral diseases are major sources of poor yields. In this assignment, we introduce a dataset of 5 fine-grained cassava leaf disease categories with 9,436 labeled images collected during a regular survey in Uganda, mostly crowdsourced from farmers taking images of their gardens, and annotated by experts at the National Crops Resources Research Institute (NaCRRI) in collaboration with the AI lab in Makarere University, Kampala. The dataset consists of leaf images of the cassava plant, with 9,436 annotated images and 12,595 unlabeled images of cassava leaves.\n",
        "\n",
        "### Goals\n",
        "\n",
        "The goal is to learn a model to classify a given image into these 4 disease categories or a 5th category indicating a healthy leaf, using the images in the training data. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubGMcRSMoZdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b599e560-bf70-4a3d-a219-af4997a290fe"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR7mMWCQkelJ"
      },
      "source": [
        "# Importing Libraries\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "from os import listdir\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# This is absolutely necessary to pull models from torchvision\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dHajGHYrRxL"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRshVN6ZkelK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7277873c-4009-4bd1-d013-c7e9014418a5"
      },
      "source": [
        "# setting the directory for the data\n",
        "## NOTE: all data was imported using the kaggle API with the following command\n",
        "# kaggle competitions download -c cassava-disease\n",
        "\n",
        "data_directory = '/content/drive/MyDrive/Colab Notebooks/cassava-disease/train'\n",
        "\n",
        "listdir()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'drive', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLbAH2uEOyGz"
      },
      "source": [
        "## Data Augmentation\r\n",
        "\r\n",
        "This set of calls will set the device for calculations as 'GPU', transform the data out-of-place for augmentation, and normalize the data. Torch allows me to do it this way so as not to have to save more data in RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr0SmT6ykelK"
      },
      "source": [
        "# setting some parameters\n",
        "n_epochs = 50\n",
        "\n",
        "# seed for reproducability\n",
        "random_seed = 1\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "# setting up GPU training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBddt38CkelL"
      },
      "source": [
        "# getting a set of augmentations to apply to the images\n",
        "train_transforms = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.Resize(500),\n",
        "        transforms.CenterCrop(500),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# getting the training data and setting up a train loader\n",
        "train_data = datasets.ImageFolder(data_directory,transform=train_transforms)\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "\n",
        "# transforming the testing data as well \n",
        "test_transforms = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.Resize(500),\n",
        "        transforms.CenterCrop(500),\n",
        "        transforms.ToTensor(),\n",
        "        # this is the normalization component, one for each channel\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Doing the same with the test data\n",
        "test_data = datasets.ImageFolder(data_directory,transform=test_transforms)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb4Yref5kelL",
        "outputId": "4d76f785-9612-43cf-a9a5-7ffb14f4f4d6"
      },
      "source": [
        "# this is for later and also to make sure that pytorch is importing the proper class names (based on the folder names)\n",
        "class_names = trainloader.dataset.classes\n",
        "class_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cbb', 'cbsd', 'cgm', 'cmd', 'healthy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBlnIxeSPGdx"
      },
      "source": [
        "## Pre-Trained Model for Transfer Learning\r\n",
        "\r\n",
        "The model chosen here will be ResNet50. A model pretrained using ImageNet data. This CNN has about 50 layers, but is not the only way I will train this model. \r\n",
        "I have decided to add two extra fully connected layers to the end, the first one with **ReLU** activation and the final one as a LogSoftmax layer. The optimizer chosen is **Adam** and the loss function chosen here is Negative Log Likelihood. The main reason for this decision is that I would need to add another layer in order to use Softmax and Cross Entropy cost instead.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIZJzMVTkelM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "fc268cfc962b46618280c9a6e66a23bf",
            "1af4bec7a61543338eb09c52b998271a",
            "ecbfd5e14d7b4a9a9ad2806e95483cf5",
            "6667a669fb8b4ac4b9b97e85c1e1ffe6",
            "7aa229df6e2d4ceda560425324c68109",
            "b9b6a0e98c7a46cfb5af7e7620fa3c23",
            "3a9478397ef340c5838f148a5412c80f",
            "d083d823d88e4c04b08f91d18f2877e9"
          ]
        },
        "outputId": "c928f946-60bc-4b20-a0e4-cef0258d741c"
      },
      "source": [
        "#importing a pretrained model\n",
        "model = models.resnet50(pretrained = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc268cfc962b46618280c9a6e66a23bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYqJRYS1kelM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ec8fcd-ffcc-4a59-e7d9-cf116472b7d2"
      },
      "source": [
        "# this is to 'freeze' the ResNet part of my model, since its already been trained\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "# this changes the final set of layers defined in 'fc' above\n",
        "# essentially, 1 Fully connected layer with ReLU activation and dropout\n",
        "# then another fully connected layer with output = 5 for the 5 classes using LogSoftmax activation\n",
        "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.2),\n",
        "                                 nn.Linear(512, 5),\n",
        "                                 nn.LogSoftmax(dim=1))\n",
        "\n",
        "# setting the loss function                                 \n",
        "criterion = nn.NLLLoss()\n",
        "# setting the optimizer as Adam\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.004)\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=5, bias=True)\n",
              "    (4): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj8Hng2AkelN"
      },
      "source": [
        "# creating a bunch of lists so that I can append the values and use them for plotting \n",
        "epoch_num, train_accuracy, test_accuracy, train_loss_list, val_loss_list = [], [], [], [], []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFA684ARQFCK"
      },
      "source": [
        "## Training loop\r\n",
        "\r\n",
        "This is just the typical training loop. This takes a **long** time, even with gpu training on Google Colab. So in order for this to run, I had to make a script to continuously add a new code chunk to make sure that Colab did not time out. Unfortunately, I still needed to be there once the model finished, since colab will still close out if nothing is running anymore (despite the script). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zchzJuiZkelN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58053299-a86f-41bf-b704-46cc56136a16"
      },
      "source": [
        "# training loop \n",
        "for epoch in range(n_epochs): \n",
        "    train_loss = 0\n",
        "    val_loss = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    #actual training\n",
        "    model.train()\n",
        "    counter = 0\n",
        "    # Train Loop\n",
        "    for inputs, labels in trainloader:\n",
        "        \n",
        "        #gpu training (on colab only)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        #zeroing the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #forward\n",
        "        output = model.forward(inputs)\n",
        "        #loss \n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        # backprop and adjusting parameters from gradient calculations\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #adding loss to the lists\n",
        "        train_loss += loss.item()*inputs.size(0)\n",
        "        counter += 1\n",
        "        #print(counter, '/', len(trainloader))\n",
        "    # evaluating the model\n",
        "    model.eval()\n",
        "    counter = 0\n",
        "\n",
        "    # Test Loop\n",
        "    #telling torch not to calculate the gradients and make no optimizer steps\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            output = model.forward(inputs)\n",
        "            #val loss calculation\n",
        "            val = criterion(output, labels)\n",
        "\n",
        "            #adding it to the existing loss\n",
        "            val_loss += val.item()*inputs.size(0)\n",
        "            #getting the real percentage by reversing the logsoftmax in the final output layer\n",
        "            output = torch.exp(output)\n",
        "            # getting the class with the highest probability from the output\n",
        "            top_p, top_class = output.topk(1, dim=1)\n",
        "            # which ones were correct\n",
        "            correct = top_class == labels.view(*top_class.shape)\n",
        "\n",
        "            #get the mean for each batch\n",
        "            accuracy += torch.mean(correct.type(torch.FloatTensor)).item()\n",
        "            counter +=1\n",
        "\n",
        "            #print(counter, '/', len(testloader))\n",
        "\n",
        "    #appending to lists\n",
        "    train_loss = train_loss/len(trainloader.dataset)\n",
        "    train_loss_list.append(train_loss)\n",
        "    valid_l = val_loss/len(testloader.dataset)\n",
        "    val_loss_list.append(valid_l)\n",
        "    train_acc = accuracy/len(trainloader)\n",
        "    train_accuracy.append(train_acc)\n",
        "    test_acc = accuracy/len(testloader)\n",
        "    test_accuracy.append(test_acc)\n",
        "    epoch_num.append(epoch)\n",
        "\n",
        "    print(f'Epoch: {epoch}, Accuracy: {test_acc}, Train loss: {train_loss}, Valid loss: {valid_l}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Accuracy: 0.7430555554433057, Train loss: 1.0688315022109758, Valid loss: 0.7055256017701124\n",
            "Epoch: 1, Accuracy: 0.8079684558561293, Train loss: 0.7431315570606032, Valid loss: 0.5353826397800715\n",
            "Epoch: 2, Accuracy: 0.8084392655367232, Train loss: 0.6888819739875901, Valid loss: 0.5310822315988312\n",
            "Epoch: 3, Accuracy: 0.8134416196979372, Train loss: 0.7471053730143179, Valid loss: 0.5340752981423994\n",
            "Epoch: 4, Accuracy: 0.8332744819969781, Train loss: 0.657041524643608, Valid loss: 0.5323506511926989\n",
            "Epoch: 5, Accuracy: 0.8149717514124294, Train loss: 0.6781770712584047, Valid loss: 0.5435106277550127\n",
            "Epoch: 6, Accuracy: 0.7670080038787281, Train loss: 0.6510141540787682, Valid loss: 0.6216956145608273\n",
            "Epoch: 7, Accuracy: 0.8274482108105374, Train loss: 0.6100321355179648, Valid loss: 0.508898572503593\n",
            "Epoch: 8, Accuracy: 0.8415136535962423, Train loss: 0.6475128087161117, Valid loss: 0.46230853590297566\n",
            "Epoch: 9, Accuracy: 0.8325682673077125, Train loss: 0.6031235681564838, Valid loss: 0.5084887807490633\n",
            "Epoch: 10, Accuracy: 0.840042372881356, Train loss: 0.6162550887343232, Valid loss: 0.46739244954252174\n",
            "Epoch: 11, Accuracy: 0.8406897362342662, Train loss: 0.5824608840733303, Valid loss: 0.48318304941374307\n",
            "Epoch: 12, Accuracy: 0.817973163841808, Train loss: 0.5931060709997148, Valid loss: 0.5053445354757417\n",
            "Epoch: 13, Accuracy: 0.8413959509235317, Train loss: 0.5935918102844433, Valid loss: 0.44144615459307246\n",
            "Epoch: 14, Accuracy: 0.8353342750651688, Train loss: 0.5681553042086719, Valid loss: 0.4683500547199135\n",
            "Epoch: 15, Accuracy: 0.8456332390591249, Train loss: 0.5995912151424349, Valid loss: 0.4364180632325514\n",
            "Epoch: 16, Accuracy: 0.8432791903194061, Train loss: 0.5799293867938083, Valid loss: 0.4200312566049028\n",
            "Epoch: 17, Accuracy: 0.825388418079096, Train loss: 0.5954697422546241, Valid loss: 0.48346346365933374\n",
            "Epoch: 18, Accuracy: 0.8282721281725135, Train loss: 0.5916441900726761, Valid loss: 0.49109109266643985\n",
            "Epoch: 19, Accuracy: 0.8502236345393509, Train loss: 0.5615260430323183, Valid loss: 0.4245158017967344\n",
            "Epoch: 20, Accuracy: 0.8430437853107344, Train loss: 0.5812653465857769, Valid loss: 0.473160353058467\n",
            "Epoch: 21, Accuracy: 0.8252118644067796, Train loss: 0.5646620940791162, Valid loss: 0.48910175712813414\n",
            "Epoch: 22, Accuracy: 0.8574034841047169, Train loss: 0.5460382436930374, Valid loss: 0.4091587839529572\n",
            "Epoch: 23, Accuracy: 0.867231638418079, Train loss: 0.5577701981030563, Valid loss: 0.417839515917372\n",
            "Epoch: 24, Accuracy: 0.8655838040308764, Train loss: 0.5710240145552445, Valid loss: 0.39794582265522727\n",
            "Epoch: 25, Accuracy: 0.8699387948391801, Train loss: 0.5315453059433879, Valid loss: 0.38899087296769846\n",
            "Epoch: 26, Accuracy: 0.8634651599630798, Train loss: 0.5395307359634733, Valid loss: 0.3890211204491039\n",
            "Epoch: 27, Accuracy: 0.8614642185679937, Train loss: 0.542117715261276, Valid loss: 0.41812857635624845\n",
            "Epoch: 28, Accuracy: 0.846457156421101, Train loss: 0.570141656016022, Valid loss: 0.44632138587966497\n",
            "Epoch: 29, Accuracy: 0.8322151599630798, Train loss: 0.5525794466786202, Valid loss: 0.4547653501534563\n",
            "Epoch: 30, Accuracy: 0.8594044254998029, Train loss: 0.5415489395403289, Valid loss: 0.40669474623243745\n",
            "Epoch: 31, Accuracy: 0.86670197740113, Train loss: 0.5607614316562615, Valid loss: 0.3810789028480333\n",
            "Epoch: 32, Accuracy: 0.8313912429378532, Train loss: 0.5552596185762103, Valid loss: 0.4629221097414699\n",
            "Epoch: 33, Accuracy: 0.8546374763472605, Train loss: 0.5344794464246219, Valid loss: 0.4243332723832704\n",
            "Epoch: 34, Accuracy: 0.8740583803020628, Train loss: 0.5374407772464833, Valid loss: 0.3834465052273857\n",
            "Epoch: 35, Accuracy: 0.8432203389830508, Train loss: 0.5161405900411592, Valid loss: 0.4329727706321564\n",
            "Epoch: 36, Accuracy: 0.8596986818448299, Train loss: 0.5459116366830202, Valid loss: 0.3938235706074066\n",
            "Epoch: 37, Accuracy: 0.8733521656127973, Train loss: 0.5624555762451474, Valid loss: 0.3911494739364195\n",
            "Epoch: 38, Accuracy: 0.8641125236527395, Train loss: 0.5586436003910265, Valid loss: 0.4010168384797502\n",
            "Epoch: 39, Accuracy: 0.8490466101694916, Train loss: 0.5532827276994686, Valid loss: 0.4340846266971619\n",
            "Epoch: 40, Accuracy: 0.8550494350282486, Train loss: 0.5473464965145861, Valid loss: 0.43126968619752215\n",
            "Epoch: 41, Accuracy: 0.8738818266297464, Train loss: 0.5319747070780569, Valid loss: 0.3982636102566119\n",
            "Epoch: 42, Accuracy: 0.8581685497935883, Train loss: 0.5225887371930577, Valid loss: 0.3989958235153552\n",
            "Epoch: 43, Accuracy: 0.872292843578899, Train loss: 0.518901604489862, Valid loss: 0.3805477312822659\n",
            "Epoch: 44, Accuracy: 0.8630532016188411, Train loss: 0.5329031822873646, Valid loss: 0.3791983661464451\n",
            "Epoch: 45, Accuracy: 0.8737641242937854, Train loss: 0.5327145944558916, Valid loss: 0.3654543775986074\n",
            "Epoch: 46, Accuracy: 0.8302730695675995, Train loss: 0.5296827273119289, Valid loss: 0.4872958213275317\n",
            "Epoch: 47, Accuracy: 0.8576388887766391, Train loss: 0.5439385393215541, Valid loss: 0.39779294044032293\n",
            "Epoch: 48, Accuracy: 0.8698799435028248, Train loss: 0.5257905834635043, Valid loss: 0.37397067956073154\n",
            "Epoch: 49, Accuracy: 0.8643479283246617, Train loss: 0.5573912547872293, Valid loss: 0.4066104353254047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HkYpZqb6qu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9029bd2-57df-438c-dcdd-5c8ec6e5d1c3"
      },
      "source": [
        "listdir()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'drive', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_EThHRCkelO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "8b19971b-f133-4f9c-b485-1bbd24217a1a"
      },
      "source": [
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "#plotting the loss \n",
        "plt.plot(epochs, train_loss_list, label = 'Training Loss')\n",
        "plt.plot(epochs, val_loss_list, label = 'Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ffb562bf240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GOrDUTcOBZ3"
      },
      "source": [
        "## Results\r\n",
        "\r\n",
        "The model performs extremely well on the validation data with a loss of approximately 0.39 over only 50 epochs. It also hovers around 86 to 89% accuracy over the entire training time. \r\n",
        "\r\n",
        "### NOTE:\r\n",
        "\r\n",
        "The model runs and runs well. However, I did not save the different loss values and accuracy values. The notebook restarted after some time and all of that information was cleared from RAM. So all I have is this graph above. I could try running it again, but the time it would take would be too much and I would like to submit this and move on. I will "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aunRChkhr92x"
      },
      "source": [
        "# Saving the model for later use (This ends the nightmare of having to train again)\r\n",
        "saved_parameters = torch.save(model.state_dict(), 'drive/MyDrive/Colab Notebooks/cassava-disease/modelstate-final.pth')\r\n",
        "saved_model = torch.save(model, 'drive/MyDrive/Colab Notebooks/cassava-disease/model-final.pth')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}